{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#To avoid warning messages\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_feature = pd.read_csv('feature_frames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant_id</th>\n",
       "      <th>product_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>order_date</th>\n",
       "      <th>user_order_seq</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ordered_before</th>\n",
       "      <th>abandoned_before</th>\n",
       "      <th>...</th>\n",
       "      <th>count_children</th>\n",
       "      <th>count_babies</th>\n",
       "      <th>count_pets</th>\n",
       "      <th>people_ex_baby</th>\n",
       "      <th>days_since_purchase_variant_id</th>\n",
       "      <th>avg_days_to_buy_variant_id</th>\n",
       "      <th>std_days_to_buy_variant_id</th>\n",
       "      <th>days_since_purchase_product_type</th>\n",
       "      <th>avg_days_to_buy_product_type</th>\n",
       "      <th>std_days_to_buy_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2807985930372</td>\n",
       "      <td>3482464092292</td>\n",
       "      <td>2020-10-05 16:46:19</td>\n",
       "      <td>2020-10-05 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808027644036</td>\n",
       "      <td>3466586718340</td>\n",
       "      <td>2020-10-05 17:59:51</td>\n",
       "      <td>2020-10-05 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808099078276</td>\n",
       "      <td>3481384026244</td>\n",
       "      <td>2020-10-05 20:08:53</td>\n",
       "      <td>2020-10-05 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808393957508</td>\n",
       "      <td>3291363377284</td>\n",
       "      <td>2020-10-06 08:57:59</td>\n",
       "      <td>2020-10-06 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808429314180</td>\n",
       "      <td>3537167515780</td>\n",
       "      <td>2020-10-06 10:37:05</td>\n",
       "      <td>2020-10-06 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       variant_id     product_type       order_id        user_id  \\\n",
       "0  33826472919172  ricepastapulses  2807985930372  3482464092292   \n",
       "1  33826472919172  ricepastapulses  2808027644036  3466586718340   \n",
       "2  33826472919172  ricepastapulses  2808099078276  3481384026244   \n",
       "3  33826472919172  ricepastapulses  2808393957508  3291363377284   \n",
       "4  33826472919172  ricepastapulses  2808429314180  3537167515780   \n",
       "\n",
       "            created_at           order_date  user_order_seq  outcome  \\\n",
       "0  2020-10-05 16:46:19  2020-10-05 00:00:00               3      0.0   \n",
       "1  2020-10-05 17:59:51  2020-10-05 00:00:00               2      0.0   \n",
       "2  2020-10-05 20:08:53  2020-10-05 00:00:00               4      0.0   \n",
       "3  2020-10-06 08:57:59  2020-10-06 00:00:00               2      0.0   \n",
       "4  2020-10-06 10:37:05  2020-10-06 00:00:00               3      0.0   \n",
       "\n",
       "   ordered_before  abandoned_before  ...  count_children  count_babies  \\\n",
       "0             0.0               0.0  ...             0.0           0.0   \n",
       "1             0.0               0.0  ...             0.0           0.0   \n",
       "2             0.0               0.0  ...             0.0           0.0   \n",
       "3             0.0               0.0  ...             0.0           0.0   \n",
       "4             0.0               0.0  ...             0.0           0.0   \n",
       "\n",
       "   count_pets  people_ex_baby days_since_purchase_variant_id  \\\n",
       "0         0.0             2.0                           33.0   \n",
       "1         0.0             2.0                           33.0   \n",
       "2         0.0             2.0                           33.0   \n",
       "3         0.0             2.0                           33.0   \n",
       "4         0.0             2.0                           33.0   \n",
       "\n",
       "   avg_days_to_buy_variant_id  std_days_to_buy_variant_id  \\\n",
       "0                        42.0                   31.134053   \n",
       "1                        42.0                   31.134053   \n",
       "2                        42.0                   31.134053   \n",
       "3                        42.0                   31.134053   \n",
       "4                        42.0                   31.134053   \n",
       "\n",
       "   days_since_purchase_product_type  avg_days_to_buy_product_type  \\\n",
       "0                              30.0                          30.0   \n",
       "1                              30.0                          30.0   \n",
       "2                              30.0                          30.0   \n",
       "3                              30.0                          30.0   \n",
       "4                              30.0                          30.0   \n",
       "\n",
       "   std_days_to_buy_product_type  \n",
       "0                      24.27618  \n",
       "1                      24.27618  \n",
       "2                      24.27618  \n",
       "3                      24.27618  \n",
       "4                      24.27618  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['variant_id', 'product_type', 'order_id', 'user_id', 'created_at',\n",
       "       'order_date', 'user_order_seq', 'outcome', 'ordered_before',\n",
       "       'abandoned_before', 'active_snoozed', 'set_as_regular',\n",
       "       'normalised_price', 'discount_pct', 'vendor', 'global_popularity',\n",
       "       'count_adults', 'count_children', 'count_babies', 'count_pets',\n",
       "       'people_ex_baby', 'days_since_purchase_variant_id',\n",
       "       'avg_days_to_buy_variant_id', 'std_days_to_buy_variant_id',\n",
       "       'days_since_purchase_product_type', 'avg_days_to_buy_product_type',\n",
       "       'std_days_to_buy_product_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_order_seq</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ordered_before</th>\n",
       "      <th>abandoned_before</th>\n",
       "      <th>active_snoozed</th>\n",
       "      <th>set_as_regular</th>\n",
       "      <th>normalised_price</th>\n",
       "      <th>...</th>\n",
       "      <th>count_children</th>\n",
       "      <th>count_babies</th>\n",
       "      <th>count_pets</th>\n",
       "      <th>people_ex_baby</th>\n",
       "      <th>days_since_purchase_variant_id</th>\n",
       "      <th>avg_days_to_buy_variant_id</th>\n",
       "      <th>std_days_to_buy_variant_id</th>\n",
       "      <th>days_since_purchase_product_type</th>\n",
       "      <th>avg_days_to_buy_product_type</th>\n",
       "      <th>std_days_to_buy_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.401250e+13</td>\n",
       "      <td>2.978388e+12</td>\n",
       "      <td>3.750025e+12</td>\n",
       "      <td>3.289342e+00</td>\n",
       "      <td>1.153669e-02</td>\n",
       "      <td>2.113868e-02</td>\n",
       "      <td>6.092589e-04</td>\n",
       "      <td>2.290188e-03</td>\n",
       "      <td>3.629864e-03</td>\n",
       "      <td>1.272808e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.492182e-02</td>\n",
       "      <td>3.538562e-03</td>\n",
       "      <td>5.134091e-02</td>\n",
       "      <td>2.072549e+00</td>\n",
       "      <td>3.312961e+01</td>\n",
       "      <td>3.523734e+01</td>\n",
       "      <td>2.645304e+01</td>\n",
       "      <td>3.143513e+01</td>\n",
       "      <td>3.088810e+01</td>\n",
       "      <td>2.594969e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.786246e+11</td>\n",
       "      <td>2.446292e+11</td>\n",
       "      <td>1.775710e+11</td>\n",
       "      <td>2.140176e+00</td>\n",
       "      <td>1.067876e-01</td>\n",
       "      <td>1.438466e-01</td>\n",
       "      <td>2.467565e-02</td>\n",
       "      <td>4.780109e-02</td>\n",
       "      <td>6.013891e-02</td>\n",
       "      <td>1.268378e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.276586e-01</td>\n",
       "      <td>5.938048e-02</td>\n",
       "      <td>3.013646e-01</td>\n",
       "      <td>3.943659e-01</td>\n",
       "      <td>3.707162e+00</td>\n",
       "      <td>1.057766e+01</td>\n",
       "      <td>7.168323e+00</td>\n",
       "      <td>1.227511e+01</td>\n",
       "      <td>4.330262e+00</td>\n",
       "      <td>3.278860e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.361529e+13</td>\n",
       "      <td>2.807986e+12</td>\n",
       "      <td>3.046041e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.599349e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.414214e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.828427e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.380354e+13</td>\n",
       "      <td>2.875152e+12</td>\n",
       "      <td>3.745901e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.394416e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.319372e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>2.427618e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.397325e+13</td>\n",
       "      <td>2.902856e+12</td>\n",
       "      <td>3.812775e+12</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.105178e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.769305e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.608188e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.428495e+13</td>\n",
       "      <td>2.922034e+12</td>\n",
       "      <td>3.874925e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.352670e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>3.059484e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.796118e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.454300e+13</td>\n",
       "      <td>3.643302e+12</td>\n",
       "      <td>5.029635e+12</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>5.868986e+01</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>3.950000e+01</td>\n",
       "      <td>3.564191e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         variant_id      order_id       user_id  user_order_seq       outcome  \\\n",
       "count  2.880549e+06  2.880549e+06  2.880549e+06    2.880549e+06  2.880549e+06   \n",
       "mean   3.401250e+13  2.978388e+12  3.750025e+12    3.289342e+00  1.153669e-02   \n",
       "std    2.786246e+11  2.446292e+11  1.775710e+11    2.140176e+00  1.067876e-01   \n",
       "min    3.361529e+13  2.807986e+12  3.046041e+12    2.000000e+00  0.000000e+00   \n",
       "25%    3.380354e+13  2.875152e+12  3.745901e+12    2.000000e+00  0.000000e+00   \n",
       "50%    3.397325e+13  2.902856e+12  3.812775e+12    3.000000e+00  0.000000e+00   \n",
       "75%    3.428495e+13  2.922034e+12  3.874925e+12    4.000000e+00  0.000000e+00   \n",
       "max    3.454300e+13  3.643302e+12  5.029635e+12    2.100000e+01  1.000000e+00   \n",
       "\n",
       "       ordered_before  abandoned_before  active_snoozed  set_as_regular  \\\n",
       "count    2.880549e+06      2.880549e+06    2.880549e+06    2.880549e+06   \n",
       "mean     2.113868e-02      6.092589e-04    2.290188e-03    3.629864e-03   \n",
       "std      1.438466e-01      2.467565e-02    4.780109e-02    6.013891e-02   \n",
       "min      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "75%      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "max      1.000000e+00      1.000000e+00    1.000000e+00    1.000000e+00   \n",
       "\n",
       "       normalised_price  ...  count_children  count_babies    count_pets  \\\n",
       "count      2.880549e+06  ...    2.880549e+06  2.880549e+06  2.880549e+06   \n",
       "mean       1.272808e-01  ...    5.492182e-02  3.538562e-03  5.134091e-02   \n",
       "std        1.268378e-01  ...    3.276586e-01  5.938048e-02  3.013646e-01   \n",
       "min        1.599349e-02  ...    0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        5.394416e-02  ...    0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        8.105178e-02  ...    0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        1.352670e-01  ...    0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max        1.000000e+00  ...    3.000000e+00  1.000000e+00  6.000000e+00   \n",
       "\n",
       "       people_ex_baby  days_since_purchase_variant_id  \\\n",
       "count    2.880549e+06                    2.880549e+06   \n",
       "mean     2.072549e+00                    3.312961e+01   \n",
       "std      3.943659e-01                    3.707162e+00   \n",
       "min      1.000000e+00                    0.000000e+00   \n",
       "25%      2.000000e+00                    3.300000e+01   \n",
       "50%      2.000000e+00                    3.300000e+01   \n",
       "75%      2.000000e+00                    3.300000e+01   \n",
       "max      5.000000e+00                    1.480000e+02   \n",
       "\n",
       "       avg_days_to_buy_variant_id  std_days_to_buy_variant_id  \\\n",
       "count                2.880549e+06                2.880549e+06   \n",
       "mean                 3.523734e+01                2.645304e+01   \n",
       "std                  1.057766e+01                7.168323e+00   \n",
       "min                  0.000000e+00                1.414214e+00   \n",
       "25%                  3.000000e+01                2.319372e+01   \n",
       "50%                  3.400000e+01                2.769305e+01   \n",
       "75%                  4.000000e+01                3.059484e+01   \n",
       "max                  8.400000e+01                5.868986e+01   \n",
       "\n",
       "       days_since_purchase_product_type  avg_days_to_buy_product_type  \\\n",
       "count                      2.880549e+06                  2.880549e+06   \n",
       "mean                       3.143513e+01                  3.088810e+01   \n",
       "std                        1.227511e+01                  4.330262e+00   \n",
       "min                        0.000000e+00                  7.000000e+00   \n",
       "25%                        3.000000e+01                  2.800000e+01   \n",
       "50%                        3.000000e+01                  3.100000e+01   \n",
       "75%                        3.000000e+01                  3.400000e+01   \n",
       "max                        1.480000e+02                  3.950000e+01   \n",
       "\n",
       "       std_days_to_buy_product_type  \n",
       "count                  2.880549e+06  \n",
       "mean                   2.594969e+01  \n",
       "std                    3.278860e+00  \n",
       "min                    2.828427e+00  \n",
       "25%                    2.427618e+01  \n",
       "50%                    2.608188e+01  \n",
       "75%                    2.796118e+01  \n",
       "max                    3.564191e+01  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Assuming numerical_cols is the list of float columns we\\'re interested in and \\'outcome\\' is a binary column in the dataframe\\nnumerical_cols = [\\'count_adults\\', \\'count_children\\', \\'count_babies\\', \\'count_pets\\', \\'avg_days_to_buy_product_type\\']\\noutcome_exists = \\'outcome\\' in df_feature.columns  # Checking if \\'outcome\\' column exists in the dataframe\\n\\nif outcome_exists:\\n    cols = 3\\n    rows = int(np.ceil(len(numerical_cols) / cols))\\n    fig, ax = plt.subplots(rows, cols, figsize=(20, 5*rows))\\n    ax = ax.flatten()\\n\\n    for i, col in enumerate(numerical_cols):\\n        sns.kdeplot(df_feature.loc[lambda x: x.outcome == 0, col], label=\\'0\\', ax=ax[i])\\n        sns.kdeplot(df_feature.loc[lambda x: x.outcome == 1, col], label=\\'1\\', ax=ax[i])\\n        ax[i].set_title(col)\\n\\n    ax[0].legend()\\n\\n    plt.tight_layout()\\nelse:\\n    print(\"The \\'outcome\\' column does not exist in the dataframe.\")\\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Assuming numerical_cols is the list of float columns we're interested in and 'outcome' is a binary column in the dataframe\n",
    "numerical_cols = ['count_adults', 'count_children', 'count_babies', 'count_pets', 'avg_days_to_buy_product_type']\n",
    "outcome_exists = 'outcome' in df_feature.columns  # Checking if 'outcome' column exists in the dataframe\n",
    "\n",
    "if outcome_exists:\n",
    "    cols = 3\n",
    "    rows = int(np.ceil(len(numerical_cols) / cols))\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(20, 5*rows))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        sns.kdeplot(df_feature.loc[lambda x: x.outcome == 0, col], label='0', ax=ax[i])\n",
    "        sns.kdeplot(df_feature.loc[lambda x: x.outcome == 1, col], label='1', ax=ax[i])\n",
    "        ax[i].set_title(col)\n",
    "\n",
    "    ax[0].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print(\"The 'outcome' column does not exist in the dataframe.\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calcula las frecuencias de las categorías\n",
    "freq_product_type = df_feature['product_type'].value_counts() / len(df_feature)\n",
    "freq_vendor = df_feature['vendor'].value_counts() / len(df_feature)\n",
    "\n",
    "# Mapea las frecuencias a las columnas originales\n",
    "df_feature['product_type'] = df_feature['product_type'].map(freq_product_type)\n",
    "df_feature['vendor'] = df_feature['vendor'].map(freq_vendor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              variant_id  product_type       order_id        user_id  \\\n",
       "0        33826472919172      0.044470  2807985930372  3482464092292   \n",
       "1        33826472919172      0.044470  2808027644036  3466586718340   \n",
       "2        33826472919172      0.044470  2808099078276  3481384026244   \n",
       "3        33826472919172      0.044470  2808393957508  3291363377284   \n",
       "4        33826472919172      0.044470  2808429314180  3537167515780   \n",
       "...                 ...           ...            ...            ...   \n",
       "2880544  33826439594116      0.007178  3643254800516  3893722808452   \n",
       "2880545  33826439594116      0.007178  3643274788996  3883757174916   \n",
       "2880546  33826439594116      0.007178  3643283734660  3874925314180   \n",
       "2880547  33826439594116      0.007178  3643294515332  3906490826884   \n",
       "2880548  33826439594116      0.007178  3643301986436  3914253959300   \n",
       "\n",
       "                  created_at           order_date  user_order_seq  outcome  \\\n",
       "0        2020-10-05 16:46:19  2020-10-05 00:00:00               3      0.0   \n",
       "1        2020-10-05 17:59:51  2020-10-05 00:00:00               2      0.0   \n",
       "2        2020-10-05 20:08:53  2020-10-05 00:00:00               4      0.0   \n",
       "3        2020-10-06 08:57:59  2020-10-06 00:00:00               2      0.0   \n",
       "4        2020-10-06 10:37:05  2020-10-06 00:00:00               3      0.0   \n",
       "...                      ...                  ...             ...      ...   \n",
       "2880544  2021-03-03 13:19:28  2021-03-03 00:00:00               3      0.0   \n",
       "2880545  2021-03-03 13:57:35  2021-03-03 00:00:00               4      0.0   \n",
       "2880546  2021-03-03 14:14:24  2021-03-03 00:00:00               7      0.0   \n",
       "2880547  2021-03-03 14:30:30  2021-03-03 00:00:00               2      0.0   \n",
       "2880548  2021-03-03 14:42:05  2021-03-03 00:00:00               3      0.0   \n",
       "\n",
       "         ordered_before  abandoned_before  ...  count_children  count_babies  \\\n",
       "0                   0.0               0.0  ...             0.0           0.0   \n",
       "1                   0.0               0.0  ...             0.0           0.0   \n",
       "2                   0.0               0.0  ...             0.0           0.0   \n",
       "3                   0.0               0.0  ...             0.0           0.0   \n",
       "4                   0.0               0.0  ...             0.0           0.0   \n",
       "...                 ...               ...  ...             ...           ...   \n",
       "2880544             0.0               0.0  ...             0.0           0.0   \n",
       "2880545             0.0               0.0  ...             0.0           0.0   \n",
       "2880546             0.0               0.0  ...             0.0           0.0   \n",
       "2880547             0.0               0.0  ...             0.0           0.0   \n",
       "2880548             0.0               0.0  ...             0.0           0.0   \n",
       "\n",
       "         count_pets  people_ex_baby  days_since_purchase_variant_id  \\\n",
       "0               0.0             2.0                            33.0   \n",
       "1               0.0             2.0                            33.0   \n",
       "2               0.0             2.0                            33.0   \n",
       "3               0.0             2.0                            33.0   \n",
       "4               0.0             2.0                            33.0   \n",
       "...             ...             ...                             ...   \n",
       "2880544         0.0             2.0                            33.0   \n",
       "2880545         0.0             2.0                            33.0   \n",
       "2880546         0.0             2.0                            33.0   \n",
       "2880547         0.0             2.0                            33.0   \n",
       "2880548         0.0             2.0                            33.0   \n",
       "\n",
       "         avg_days_to_buy_variant_id  std_days_to_buy_variant_id  \\\n",
       "0                              42.0                   31.134053   \n",
       "1                              42.0                   31.134053   \n",
       "2                              42.0                   31.134053   \n",
       "3                              42.0                   31.134053   \n",
       "4                              42.0                   31.134053   \n",
       "...                             ...                         ...   \n",
       "2880544                        34.0                   27.693045   \n",
       "2880545                        34.0                   27.693045   \n",
       "2880546                        34.0                   27.693045   \n",
       "2880547                        34.0                   27.693045   \n",
       "2880548                        34.0                   27.693045   \n",
       "\n",
       "         days_since_purchase_product_type  avg_days_to_buy_product_type  \\\n",
       "0                                    30.0                          30.0   \n",
       "1                                    30.0                          30.0   \n",
       "2                                    30.0                          30.0   \n",
       "3                                    30.0                          30.0   \n",
       "4                                    30.0                          30.0   \n",
       "...                                   ...                           ...   \n",
       "2880544                              30.0                          34.0   \n",
       "2880545                              30.0                          34.0   \n",
       "2880546                              30.0                          34.0   \n",
       "2880547                              30.0                          34.0   \n",
       "2880548                              30.0                          34.0   \n",
       "\n",
       "         std_days_to_buy_product_type  \n",
       "0                           24.276180  \n",
       "1                           24.276180  \n",
       "2                           24.276180  \n",
       "3                           24.276180  \n",
       "4                           24.276180  \n",
       "...                               ...  \n",
       "2880544                     27.451392  \n",
       "2880545                     27.451392  \n",
       "2880546                     27.451392  \n",
       "2880547                     27.451392  \n",
       "2880548                     27.451392  \n",
       "\n",
       "[2880549 rows x 27 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Asumiendo que 'df' es tu DataFrame y 'order_date' y 'created_at' son tus columnas de fecha\n",
    "\n",
    "# Primero, asegúrate de que pandas reconoce tus columnas de fecha como datetime\n",
    "df_feature['order_date'] = pd.to_datetime(df_feature['order_date'])\n",
    "df_feature['created_at'] = pd.to_datetime(df_feature['created_at'])\n",
    "\n",
    "# Descomponer 'order_date' en año, mes y día\n",
    "df_feature['order_year'] = df_feature['order_date'].dt.year\n",
    "df_feature['order_month'] = df_feature['order_date'].dt.month\n",
    "df_feature['order_day'] = df_feature['order_date'].dt.day\n",
    "\n",
    "# Extraer información de la hora de 'created_at'\n",
    "df_feature['created_hour'] = df_feature['created_at'].dt.hour\n",
    "\n",
    "# Opcional: Extraer más características como día de la semana o si es fin de semana\n",
    "df_feature['order_dayofweek'] = df_feature['order_date'].dt.dayofweek\n",
    "df_feature['order_is_weekend'] = df_feature['order_date'].dt.dayofweek >= 5\n",
    "\n",
    "# Ahora puedes eliminar las columnas originales de fecha si ya no las necesitas\n",
    "df_feature.drop(['order_date', 'created_at'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880549, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant_id</th>\n",
       "      <th>product_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_order_seq</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ordered_before</th>\n",
       "      <th>abandoned_before</th>\n",
       "      <th>active_snoozed</th>\n",
       "      <th>set_as_regular</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_days_to_buy_variant_id</th>\n",
       "      <th>std_days_to_buy_variant_id</th>\n",
       "      <th>days_since_purchase_product_type</th>\n",
       "      <th>avg_days_to_buy_product_type</th>\n",
       "      <th>std_days_to_buy_product_type</th>\n",
       "      <th>order_year</th>\n",
       "      <th>order_month</th>\n",
       "      <th>order_day</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>order_dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "      <td>2.880549e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.401250e+13</td>\n",
       "      <td>2.762532e-02</td>\n",
       "      <td>2.978388e+12</td>\n",
       "      <td>3.750025e+12</td>\n",
       "      <td>3.289342e+00</td>\n",
       "      <td>1.153669e-02</td>\n",
       "      <td>2.113868e-02</td>\n",
       "      <td>6.092589e-04</td>\n",
       "      <td>2.290188e-03</td>\n",
       "      <td>3.629864e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.523734e+01</td>\n",
       "      <td>2.645304e+01</td>\n",
       "      <td>3.143513e+01</td>\n",
       "      <td>3.088810e+01</td>\n",
       "      <td>2.594969e+01</td>\n",
       "      <td>2.020684e+03</td>\n",
       "      <td>4.696157e+00</td>\n",
       "      <td>1.549961e+01</td>\n",
       "      <td>1.424203e+01</td>\n",
       "      <td>2.905320e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.786246e+11</td>\n",
       "      <td>1.874006e-02</td>\n",
       "      <td>2.446292e+11</td>\n",
       "      <td>1.775710e+11</td>\n",
       "      <td>2.140176e+00</td>\n",
       "      <td>1.067876e-01</td>\n",
       "      <td>1.438466e-01</td>\n",
       "      <td>2.467565e-02</td>\n",
       "      <td>4.780109e-02</td>\n",
       "      <td>6.013891e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057766e+01</td>\n",
       "      <td>7.168323e+00</td>\n",
       "      <td>1.227511e+01</td>\n",
       "      <td>4.330262e+00</td>\n",
       "      <td>3.278860e+00</td>\n",
       "      <td>4.649840e-01</td>\n",
       "      <td>4.523839e+00</td>\n",
       "      <td>8.743562e+00</td>\n",
       "      <td>4.741962e+00</td>\n",
       "      <td>2.028230e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.361529e+13</td>\n",
       "      <td>9.095488e-04</td>\n",
       "      <td>2.807986e+12</td>\n",
       "      <td>3.046041e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.414214e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.828427e+00</td>\n",
       "      <td>2.020000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.380354e+13</td>\n",
       "      <td>1.575429e-02</td>\n",
       "      <td>2.875152e+12</td>\n",
       "      <td>3.745901e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.319372e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>2.427618e+01</td>\n",
       "      <td>2.020000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.397325e+13</td>\n",
       "      <td>2.015866e-02</td>\n",
       "      <td>2.902856e+12</td>\n",
       "      <td>3.812775e+12</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.769305e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.608188e+01</td>\n",
       "      <td>2.021000e+03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.428495e+13</td>\n",
       "      <td>3.826875e-02</td>\n",
       "      <td>2.922034e+12</td>\n",
       "      <td>3.874925e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>3.059484e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.796118e+01</td>\n",
       "      <td>2.021000e+03</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.454300e+13</td>\n",
       "      <td>7.862182e-02</td>\n",
       "      <td>3.643302e+12</td>\n",
       "      <td>5.029635e+12</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>5.868986e+01</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>3.950000e+01</td>\n",
       "      <td>3.564191e+01</td>\n",
       "      <td>2.021000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         variant_id  product_type      order_id       user_id  user_order_seq  \\\n",
       "count  2.880549e+06  2.880549e+06  2.880549e+06  2.880549e+06    2.880549e+06   \n",
       "mean   3.401250e+13  2.762532e-02  2.978388e+12  3.750025e+12    3.289342e+00   \n",
       "std    2.786246e+11  1.874006e-02  2.446292e+11  1.775710e+11    2.140176e+00   \n",
       "min    3.361529e+13  9.095488e-04  2.807986e+12  3.046041e+12    2.000000e+00   \n",
       "25%    3.380354e+13  1.575429e-02  2.875152e+12  3.745901e+12    2.000000e+00   \n",
       "50%    3.397325e+13  2.015866e-02  2.902856e+12  3.812775e+12    3.000000e+00   \n",
       "75%    3.428495e+13  3.826875e-02  2.922034e+12  3.874925e+12    4.000000e+00   \n",
       "max    3.454300e+13  7.862182e-02  3.643302e+12  5.029635e+12    2.100000e+01   \n",
       "\n",
       "            outcome  ordered_before  abandoned_before  active_snoozed  \\\n",
       "count  2.880549e+06    2.880549e+06      2.880549e+06    2.880549e+06   \n",
       "mean   1.153669e-02    2.113868e-02      6.092589e-04    2.290188e-03   \n",
       "std    1.067876e-01    1.438466e-01      2.467565e-02    4.780109e-02   \n",
       "min    0.000000e+00    0.000000e+00      0.000000e+00    0.000000e+00   \n",
       "25%    0.000000e+00    0.000000e+00      0.000000e+00    0.000000e+00   \n",
       "50%    0.000000e+00    0.000000e+00      0.000000e+00    0.000000e+00   \n",
       "75%    0.000000e+00    0.000000e+00      0.000000e+00    0.000000e+00   \n",
       "max    1.000000e+00    1.000000e+00      1.000000e+00    1.000000e+00   \n",
       "\n",
       "       set_as_regular  ...  avg_days_to_buy_variant_id  \\\n",
       "count    2.880549e+06  ...                2.880549e+06   \n",
       "mean     3.629864e-03  ...                3.523734e+01   \n",
       "std      6.013891e-02  ...                1.057766e+01   \n",
       "min      0.000000e+00  ...                0.000000e+00   \n",
       "25%      0.000000e+00  ...                3.000000e+01   \n",
       "50%      0.000000e+00  ...                3.400000e+01   \n",
       "75%      0.000000e+00  ...                4.000000e+01   \n",
       "max      1.000000e+00  ...                8.400000e+01   \n",
       "\n",
       "       std_days_to_buy_variant_id  days_since_purchase_product_type  \\\n",
       "count                2.880549e+06                      2.880549e+06   \n",
       "mean                 2.645304e+01                      3.143513e+01   \n",
       "std                  7.168323e+00                      1.227511e+01   \n",
       "min                  1.414214e+00                      0.000000e+00   \n",
       "25%                  2.319372e+01                      3.000000e+01   \n",
       "50%                  2.769305e+01                      3.000000e+01   \n",
       "75%                  3.059484e+01                      3.000000e+01   \n",
       "max                  5.868986e+01                      1.480000e+02   \n",
       "\n",
       "       avg_days_to_buy_product_type  std_days_to_buy_product_type  \\\n",
       "count                  2.880549e+06                  2.880549e+06   \n",
       "mean                   3.088810e+01                  2.594969e+01   \n",
       "std                    4.330262e+00                  3.278860e+00   \n",
       "min                    7.000000e+00                  2.828427e+00   \n",
       "25%                    2.800000e+01                  2.427618e+01   \n",
       "50%                    3.100000e+01                  2.608188e+01   \n",
       "75%                    3.400000e+01                  2.796118e+01   \n",
       "max                    3.950000e+01                  3.564191e+01   \n",
       "\n",
       "         order_year   order_month     order_day  created_hour  order_dayofweek  \n",
       "count  2.880549e+06  2.880549e+06  2.880549e+06  2.880549e+06     2.880549e+06  \n",
       "mean   2.020684e+03  4.696157e+00  1.549961e+01  1.424203e+01     2.905320e+00  \n",
       "std    4.649840e-01  4.523839e+00  8.743562e+00  4.741962e+00     2.028230e+00  \n",
       "min    2.020000e+03  1.000000e+00  1.000000e+00  0.000000e+00     0.000000e+00  \n",
       "25%    2.020000e+03  1.000000e+00  8.000000e+00  1.100000e+01     1.000000e+00  \n",
       "50%    2.021000e+03  2.000000e+00  1.600000e+01  1.400000e+01     3.000000e+00  \n",
       "75%    2.021000e+03  1.100000e+01  2.300000e+01  1.800000e+01     5.000000e+00  \n",
       "max    2.021000e+03  1.200000e+01  3.100000e+01  2.300000e+01     6.000000e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_feature.shape)\n",
    "df_feature.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "\n",
    "group_column = 'user_id'\n",
    "# Inicializa el divisor con GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.7, test_size=0.3, random_state=42)\n",
    "\n",
    "# Realiza la división manteniendo 'user_id' o 'order_id' agrupados\n",
    "for train_idx, test_idx in gss.split(df_feature, groups=df_feature[group_column]):\n",
    "    train_val = df_feature.iloc[train_idx]\n",
    "    test = df_feature.iloc[test_idx]\n",
    "\n",
    "# Elimina la columna 'outcome' para obtener X_train_val y X_test\n",
    "X_train_val = train_val.drop('outcome', axis=1).values\n",
    "X_test = test.drop('outcome', axis=1).values\n",
    "y_train_val = train_val['outcome'].values\n",
    "y_test = test['outcome'].values\n",
    "\n",
    "# Ahora divide train_val en train y val\n",
    "train_val_gss = GroupShuffleSplit(n_splits=1, train_size=(5/7), test_size=(2/7), random_state=42)\n",
    "\n",
    "for train_idx, val_idx in train_val_gss.split(train_val, groups=train_val[group_column]):\n",
    "    train = train_val.iloc[train_idx]\n",
    "    val = train_val.iloc[val_idx]\n",
    "\n",
    "# Finalmente, elimina la columna 'outcome' para obtener X_train, X_val y sus respectivos y\n",
    "X_train = train.drop('outcome', axis=1).values\n",
    "X_val = val.drop('outcome', axis=1).values\n",
    "y_train = train['outcome'].values\n",
    "y_val = val['outcome'].values\n",
    "\n",
    "# Ahora puedes eliminar la columna 'outcome' de df_feature si fue añadida solo para la división\n",
    "df_feature.drop('outcome', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1446128, 30)\n",
      "(568780, 30)\n",
      "(865641, 30)\n",
      "(1446128,)\n",
      "(568780,)\n",
      "(865641,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  \n",
    "print(X_val.shape)  \n",
    "print(X_test.shape)  \n",
    "\n",
    "print(y_train.shape)  \n",
    "print(y_val.shape)  \n",
    "print(y_test.shape)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos train, val y test sin leakage de 'user_id' o 'order_id' , si agrupamos por user, eso engloba order id , puesto q en la misma orden el user es el mismo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar solo las columnas que no son cíclicas o no numéricas\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s= scaler.transform(X_val)\n",
    "X_test_s= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET\n",
      "Mean of each feature:  [-0.  0. -0. -0. -0. -0.  0.  0.  0.  0. -0. -0. -0.  0.  0. -0.  0.  0.\n",
      " -0. -0.  0. -0. -0. -0.  0. -0. -0. -0.  0.  0.]\n",
      "Std of each feature:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "VALIDATION SET\n",
      "Mean of each feature:  [ 0.01 -0.    0.07  0.13 -0.14 -0.02 -0.01 -0.03  0.01  0.   -0.   -0.\n",
      " -0.   -0.05 -0.1  -0.08  0.02 -0.11  0.   -0.01 -0.01  0.01 -0.01 -0.01\n",
      "  0.06 -0.04 -0.08 -0.   -0.05 -0.04]\n",
      "Std of each feature:  [1.01 1.   1.07 0.87 0.66 0.95 0.81 0.69 1.07 1.   1.   1.   1.   0.53\n",
      " 0.71 0.   1.29 0.65 0.96 1.   1.   0.97 1.01 1.01 0.98 0.98 1.01 1.04\n",
      " 1.01 0.98]\n",
      "\n",
      "TEST SET\n",
      "Mean of each feature:  [ 0.   -0.   -0.01  0.07  0.03  0.02  0.    0.01  0.    0.    0.   -0.\n",
      " -0.   -0.12 -0.09 -0.08 -0.01 -0.13  0.01 -0.   -0.    0.   -0.   -0.\n",
      "  0.03 -0.03 -0.08 -0.03 -0.05 -0.03]\n",
      "Std of each feature:  [1.   1.   0.98 0.91 1.14 1.05 1.02 1.09 1.03 1.   1.   1.   1.   0.55\n",
      " 0.76 0.   1.31 0.57 1.1  1.   1.   1.03 1.   1.   0.99 0.98 1.   1.02\n",
      " 1.02 0.99]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print('TRAINING SET')\n",
    "print('Mean of each feature: ', np.round(np.mean(X_train_s,0),2))\n",
    "print('Std of each feature: ', np.round(np.std(X_train_s,0),2))\n",
    "print('\\nVALIDATION SET')\n",
    "print('Mean of each feature: ', np.round(np.mean(X_val_s,0),2))\n",
    "print('Std of each feature: ', np.round(np.std(X_val_s,0),2))\n",
    "print('\\nTEST SET')\n",
    "print('Mean of each feature: ', np.round(np.mean(X_test_s,0),2))\n",
    "print('Std of each feature: ', np.round(np.std(X_test_s,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.44\n",
      "97.18\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mround\u001b[39m(Score_LDA_train\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mround\u001b[39m(LDA_score\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m(y_test, predict_LDA)\n\u001b[1;32m     14\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, predict_LDA)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mround\u001b[39m(Score_LR_train\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda.fit(X_train_s, y_train)\n",
    "predict_LDA= lda.predict(X_test_s);\n",
    "Score_LDA_train = lda.score(X_train_s, y_train)\n",
    "LDA_score = lda.score(X_test_s, y_test)\n",
    "print(round(Score_LDA_train*100,2))\n",
    "print(round(LDA_score*100,2))\n",
    "\n",
    "precision = precision_score(y_test, predict_LDA)\n",
    "recall = recall_score(y_test, predict_LDA)\n",
    "\n",
    "print(round(Score_LR_train*100,2))\n",
    "print(round(LR_score*100,2))\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adri/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/adri/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/adri/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/adri/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/adri/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/adri/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00033793 0.00033793 0.00033793 0.00033793 0.00033793 0.00033793\n",
      "  0.00033793]\n",
      " [0.00033615 0.00033793 0.00033793 0.00033793 0.00033793 0.00033793\n",
      "  0.00033793]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Asegúrate de que tus conjuntos de datos están definidos: X_train_s, y_train, X_val_s, y_val\n",
    "\n",
    "penalty = (None, 'l2')\n",
    "C = [0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "\n",
    "l_penalty = len(penalty)\n",
    "l_C = len(C)\n",
    "results_lr = np.zeros((l_penalty, l_C))\n",
    "\n",
    "for i in range(len(penalty)):\n",
    "    for j in range(len(C)):\n",
    "        penalty_k = penalty[i]\n",
    "        C_k = C[j]\n",
    "        lr = LogisticRegression(C=C_k, penalty=penalty_k, solver='lbfgs', max_iter=10000)\n",
    "        lr.fit(X_train_s, y_train)\n",
    "        y_pred = lr.predict(X_val_s)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "        error_tipo_1 = fp / (fp + tn) if (fp + tn) > 0 else 0  # Evita la división por cero\n",
    "        results_lr[i][j] = error_tipo_1\n",
    "\n",
    "print(results_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best penalty is:  None\n",
      "The best C is:  0.01\n"
     ]
    }
   ],
   "source": [
    "best_params_lr = np.max(results_lr)  # Buscamos valor max de la\n",
    "pos = np.where(results_lr == best_params_lr)  # Buscamos su posición\n",
    "best_penalty_index = pos[0][0]\n",
    "best_C_index = pos[1][0]\n",
    "\n",
    "print('The best penalty is: ', penalty[best_penalty_index])\n",
    "print('The best C is: ', C[best_C_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.92\n",
      "98.82\n",
      "Precision: 0.6539618856569709\n",
      "Recall: 0.06191832858499525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "lr_best = LogisticRegression(penalty='l2', C=0.1)\n",
    "lr_best.fit(X_train_s, y_train)\n",
    "y_lr_best = lr_best.predict(X_test_s)\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, y_lr_best)\n",
    "recall = recall_score(y_test, y_lr_best)\n",
    "Score_LR_train = lr_best.score(X_train_s, y_train)\n",
    "LR_score = lr_best.score(X_test_s, y_test)\n",
    "\n",
    "print(round(Score_LR_train*100,2))\n",
    "print(round(LR_score*100,2))\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la precision es la leche porque pone un monton de 0s pero los unos se le da bastante mal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00983022 0.00983022]\n",
      " [0.00113473 0.00174479]\n",
      " [0.00035572 0.00085905]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Asegúrate de que tus conjuntos de datos están definidos: X_train_s, y_train, X_val_s, y_val\n",
    "\n",
    "n_neighbors = [1,5,10]\n",
    "weights = ('uniform', 'distance')\n",
    "\n",
    "l_n_neighbors = len(n_neighbors)\n",
    "l_weights = len(weights)\n",
    "results_knn = np.zeros((l_n_neighbors, l_weights))\n",
    "\n",
    "for i in range(len(n_neighbors)):\n",
    "    for j in range(len(weights)):\n",
    "        n_neighbors_k = n_neighbors[i]\n",
    "        weights_k = weights[j]\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors_k, weights=weights_k)\n",
    "        knn.fit(X_train_s, y_train)\n",
    "        y_pred = knn.predict(X_val_s)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "        # Error de Tipo I: FP / (FP + TN)\n",
    "        error_tipo_1 = fp / (fp + tn) if (fp + tn) > 0 else 0  # Evita la división por cero\n",
    "        results_knn[i][j] = error_tipo_1\n",
    "\n",
    "print(results_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "me tardo como 3h en entrenar y los resultados no son muy buenos : [[0.00983022 0.00983022]\n",
    " [0.00113473 0.00174479]\n",
    " [0.00035572 0.00085905]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (12264489.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    results_knn = [0.00983022 0.00983022], [0.00113473 0.00174479], [0.00035572 0.00085905]\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "results_knn = [0.00983022 0.00983022], [0.00113473 0.00174479], [0.00035572 0.00085905]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "best_params_knn = np.max(results_knn)  # Buscamos valor max de la\n",
    "pos = np.where(results_knn == best_params_knn)  # Buscamos su posición\n",
    "best_penalty_index = pos[0][0]\n",
    "best_C_index = pos[1][0]\n",
    "\n",
    "print('The best penalty is: ', penalty[best_penalty_index])\n",
    "print('The best C is: ', C[best_C_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
